{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import pymysql\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# SQL functions\n",
    "import pymysql\n",
    "endpoint = 'ta10projectinstance1.c0m59tujlbqm.ap-southeast-2.rds.amazonaws.com'\n",
    "username = 'admin'\n",
    "password = 'fit5120ta10'\n",
    "database_name = 'fit5120_i3_schema'\n",
    "client_flag = 'CLIENT.MULTI_STATEMENTS'\n",
    "\n",
    "connection = pymysql.connect(host = endpoint, user = username, passwd = password, db = database_name)\n",
    "\n",
    "# Function used to clear all entries in a single table considering no indexes or Foreign keys are present\n",
    "def truncate_handler(table):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"\"\"TRUNCATE {}\"\"\".format(table))\n",
    "    connection.commit()\n",
    "    return 'table {} has been truncated'.format(table)\n",
    "\n",
    "def country_region_handler(values):\n",
    "    query = \"\"\"INSERT INTO country_region (country_region_id, country_code, region_name) VALUES (%s, %s, %s)\"\"\"\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query, values)\n",
    "    connection.commit()\n",
    "    return 'import successful {}'.format(values)\n",
    "\n",
    "def country_handler(values):\n",
    "    query = \"\"\"INSERT INTO country (country_name, country_code) VALUES (%s, %s)\"\"\"\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query, values)\n",
    "    connection.commit()\n",
    "    return 'import successful {}'.format(values)\n",
    "\n",
    "def symptom_handler(values):\n",
    "    query = \"\"\"INSERT INTO symptom (symp_id, symp_name) VALUES (%s, %s)\"\"\"\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query, values)\n",
    "    connection.commit()\n",
    "    return 'import successful {}'.format(values)\n",
    "\n",
    "def case_details_handler(values):\n",
    "    query = \"\"\"INSERT INTO case_details (case_id, symp_id) VALUES (%s, %s)\"\"\"\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query, values)\n",
    "    connection.commit()\n",
    "    return 'import successful {}'.format(values)\n",
    "\n",
    "def case_handler(values):\n",
    "    query = \"\"\"INSERT INTO `case` (case_id, case_status, case_date, case_gender, country_region_id, case_death_date) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query, values)\n",
    "    connection.commit()\n",
    "    return 'import successful {}'.format(values)\n",
    "\n",
    "def prediction_handler(values):\n",
    "    query = \"\"\"INSERT INTO predictions (country_region_id, pred_date, pred_count) VALUES (%s, %s, %s)\"\"\"\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query, values)\n",
    "    connection.commit()\n",
    "    return 'predictions table has been updated'\n",
    "\n",
    "def query(query):\n",
    "    sql_query = \"\"\"{}\"\"\".format(query)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(sql_query)\n",
    "    return cursor.fetchall()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "def prediction():\n",
    "    vic_aug = pd.read_csv(\"https://raw.githubusercontent.com/owid/monkeypox/main/owid-monkeypox-data.csv\") # reading the file\n",
    "    vic_aug=vic_aug.query('location==\"Australia\"') #filtering for australia\n",
    "    vic_aug=vic_aug.reset_index() #reseting index\n",
    "    vic_aug = vic_aug[['date', 'new_cases_smoothed']] #subselection of attributes\n",
    "    EndDate = date.today() + timedelta(days=5)#getting the days from current datetime\n",
    "    sdate=vic_aug.iloc[0,:]['date']#getting the start date\n",
    "    sdate=datetime.strptime(sdate,'%Y-%m-%d').date()#converting to datetime format\n",
    "    time_range=pd.date_range(sdate,EndDate-timedelta(days=1),freq='d')#retrieving the dates \n",
    "    time_range=time_range.to_frame(index=False, name='date') #converting it to a dataframe\n",
    "    time_range['date']=time_range['date'].astype(str) #Converting to string datatype\n",
    "    merged_df=pd.merge(time_range,vic_aug,on='date',how='left') #left joining\n",
    "    merged_df[\"new_cases_smoothed\"].fillna(0, inplace=True)#replacing predicted values to initially 0\n",
    "    step_fit=auto_arima(merged_df['new_cases_smoothed'],trace=True,suppress_warnings=True) #stepwise function for auto arima\n",
    "    model = ARIMA(merged_df.new_cases_smoothed, order=step_fit.get_params().get(\"order\")) # fetching the best parameters\n",
    "    #model=ARIMA(train[''],order=(3,1,0))\n",
    "    model=model.fit()\n",
    "    train=merged_df.iloc[:-100] #splitting training and testing\n",
    "    test=merged_df.iloc[-100:]\n",
    "    start=len(test)\n",
    "    end=len(train)+len(test)-1\n",
    "    pred=model.predict(start=start,end=end,typ='levels') #predicting the values\n",
    "    series1 = pred.to_frame()\n",
    "    series1['predicted_mean'] = series1['predicted_mean'].abs() #taking absolute values\n",
    "    series1['predicted_mean']=series1['predicted_mean'].apply(np.floor)  #flooring the values\n",
    "    series1=series1.iloc[-5:]\n",
    "    test=test.iloc[-5:]\n",
    "    test['pred']=series1['predicted_mean']\n",
    "    test=test[['date','pred']]\n",
    "    return test #returning the dataframe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main function to run the model, truncate the prediction table and push the new data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "def main():\n",
    "    # runs the model\n",
    "    df = prediction() \n",
    "    # renames all the columns to the appropriate format for the relational database\n",
    "    df = df.rename(columns = {'date': 'pred_date', 'pred':'pred_count'})\n",
    "    # Adds the country_region_id by default it will be AUS_0 due to naming convention\n",
    "    df['country_region_id'] = 'AUS_0'\n",
    "    # truncates the prediction table\n",
    "    truncate_handler('predictions')\n",
    "    # uploads the new data into the predictions table\n",
    "    p_df = df.copy()\n",
    "    for row in range(0,p_df.shape[0]):\n",
    "        in_tuple = tuple(p_df.iloc[row, :])\n",
    "        prediction_handler((in_tuple[2], in_tuple[0], in_tuple[1]))\n",
    "    return 'prediction table has been updated'\n",
    "main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=161.064, Time=0.07 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=181.187, Time=0.01 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=176.857, Time=0.01 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=173.166, Time=0.05 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=179.190, Time=0.01 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0] intercept   : AIC=173.880, Time=0.04 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=173.767, Time=0.03 sec\n",
      " ARIMA(3,1,2)(0,0,0)[0] intercept   : AIC=177.644, Time=0.07 sec\n",
      " ARIMA(2,1,3)(0,0,0)[0] intercept   : AIC=162.585, Time=0.13 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=172.633, Time=0.03 sec\n",
      " ARIMA(1,1,3)(0,0,0)[0] intercept   : AIC=175.853, Time=0.06 sec\n",
      " ARIMA(3,1,1)(0,0,0)[0] intercept   : AIC=175.644, Time=0.02 sec\n",
      " ARIMA(3,1,3)(0,0,0)[0] intercept   : AIC=165.003, Time=0.13 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0]             : AIC=159.067, Time=0.05 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0]             : AIC=171.889, Time=0.01 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0]             : AIC=171.775, Time=0.02 sec\n",
      " ARIMA(3,1,2)(0,0,0)[0]             : AIC=175.652, Time=0.05 sec\n",
      " ARIMA(2,1,3)(0,0,0)[0]             : AIC=160.589, Time=0.09 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0]             : AIC=170.642, Time=0.02 sec\n",
      " ARIMA(1,1,3)(0,0,0)[0]             : AIC=173.862, Time=0.04 sec\n",
      " ARIMA(3,1,1)(0,0,0)[0]             : AIC=173.652, Time=0.02 sec\n",
      " ARIMA(3,1,3)(0,0,0)[0]             : AIC=163.011, Time=0.12 sec\n",
      "\n",
      "Best model:  ARIMA(2,1,2)(0,0,0)[0]          \n",
      "Total fit time: 1.078 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Query to check the new data in the prediction table"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "query('SELECT * FROM predictions')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(('AUS_0', '2022-10-08', 0),\n",
       " ('AUS_0', '2022-10-09', 0),\n",
       " ('AUS_0', '2022-10-10', 0),\n",
       " ('AUS_0', '2022-10-11', 0),\n",
       " ('AUS_0', '2022-10-12', 0))"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.0 64-bit ('3.10.0')"
  },
  "interpreter": {
   "hash": "9204fa191f0fcaf9c61ca1f5ff3a4df7ba6fcba2c3c547282aeaf746cdc365de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}